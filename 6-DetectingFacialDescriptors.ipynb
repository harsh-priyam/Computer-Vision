{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3jiX_h-KN_92"
      },
      "outputs": [],
      "source": [
        "import dlib\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "path = '/content/drive/MyDrive/Datasets/yalefaces.zip'\n",
        "zip_object = zipfile.ZipFile(file=path, mode = 'r')\n",
        "zip_object.extractall('./')\n",
        "zip_object.close()"
      ],
      "metadata": {
        "id": "JpxZ50UoQA49"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_detector = dlib.get_frontal_face_detector()\n",
        "points_detector = dlib.shape_predictor('/content/drive/MyDrive/Weights/shape_predictor_68_face_landmarks.dat')\n",
        "face_descriptor_extractor = dlib.face_recognition_model_v1('/content/drive/MyDrive/Weights/dlib_face_recognition_resnet_model_v1.dat')"
      ],
      "metadata": {
        "id": "qYmpUHTAOSfF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = {}\n",
        "idx=0\n",
        "face_descriptors = None\n",
        "\n",
        "paths = [os.path.join('/content/yalefaces/train',f) for f in os.listdir('/content/yalefaces/train')]\n",
        "for path in paths:\n",
        "  # print(path)\n",
        "  image = Image.open(path).convert('RGB')\n",
        "  image_np = np.array(image,'uint8')\n",
        "  face_detection = face_detector(image_np,1)\n",
        "  for face in face_detection:\n",
        "    l,t,r,b = face.left(), face.top(), face.right(), face.bottom()\n",
        "    cv2.rectangle(image_np,(l,t),(r,b),(0,0,255),2)\n",
        "    points = points_detector(image_np,face)\n",
        "    for point in points.parts():\n",
        "      cv2.circle(image_np,(point.x, point.y),2,(0,255,0),1)\n",
        "    face_descriptor = face_descriptor_extractor.compute_face_descriptor(image_np,points)\n",
        "    face_descriptor = [f for f in face_descriptor]\n",
        "    face_descriptor = np.array(face_descriptor,dtype=np.float64)\n",
        "    face_descriptor = face_descriptor[np.newaxis, :]\n",
        "    # print(face_descriptor)\n",
        "    if face_descriptors is None:\n",
        "      face_descriptors = face_descriptor\n",
        "    else:\n",
        "      face_descriptors = np.concatenate((face_descriptors,face_descriptor),axis=0)\n",
        "\n",
        "    index[idx] = path \n",
        "    idx += 1      \n",
        "\n",
        "  # cv2_imshow(image_np)  \n"
      ],
      "metadata": {
        "id": "ezXb_oEePQSn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_descriptors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDKnc5u0RzYZ",
        "outputId": "0ae74283-a00d-4504-c95d-85c1ac88f623"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(132, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face_descriptors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "davlNbVeYOUl",
        "outputId": "15467797-7669-4b74-bf28-88e0f4afe2ed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.15016598,  0.08190971, -0.00158949, ..., -0.02205639,\n",
              "         0.11158851,  0.05841742],\n",
              "       [-0.16750331,  0.04092948,  0.07239178, ...,  0.02982324,\n",
              "         0.11341026,  0.05801933],\n",
              "       [-0.09758417,  0.01798972, -0.09853616, ..., -0.00577495,\n",
              "        -0.01994056,  0.06262899],\n",
              "       ...,\n",
              "       [-0.1402103 ,  0.07552125,  0.01510925, ...,  0.01090842,\n",
              "         0.06845607,  0.0286531 ],\n",
              "       [-0.20720418,  0.09235502,  0.05147153, ..., -0.03726506,\n",
              "         0.0900088 ,  0.06165224],\n",
              "       [-0.12021624,  0.11514573,  0.08716735, ..., -0.02592804,\n",
              "         0.18188372,  0.00609227]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xa5UDMDYYZuY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}